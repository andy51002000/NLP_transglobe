{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pylab as pl #繪圖\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下來，我們將設置模型超參數，輸入層的大小設置為7，這意味著我們將有6個上下文神經元和1個輸入神經元，seq_length定義我們的輸入和目標序列的長度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "input_size = 7\n",
    "hidden_size = 6\n",
    "output_size = 1\n",
    "epochs = 300\n",
    "seq_length = 20 #輸入長度，RNN的序列，這數字來自於data要放入的長度\n",
    "lr = 0.1 #學習率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time_steps = np.linspace(2, 10, seq_length + 1) #指定區間產生平均的數值，產生2~10共21個，畫圖區間使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2. ,  2.4,  2.8,  3.2,  3.6,  4. ,  4.4,  4.8,  5.2,  5.6,  6. ,\n",
       "        6.4,  6.8,  7.2,  7.6,  8. ,  8.4,  8.8,  9.2,  9.6, 10. ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.sin(data_time_steps) #轉sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.90929743,  0.67546318,  0.33498815, -0.05837414, -0.44252044,\n",
       "       -0.7568025 , -0.95160207, -0.99616461, -0.88345466, -0.63126664,\n",
       "       -0.2794155 ,  0.1165492 ,  0.49411335,  0.79366786,  0.96791967,\n",
       "        0.98935825,  0.85459891,  0.58491719,  0.22288991, -0.17432678,\n",
       "       -0.54402111])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.resize((seq_length + 1, 1))#調整成1行,21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90929743],\n",
       "       [ 0.67546318],\n",
       "       [ 0.33498815],\n",
       "       [-0.05837414],\n",
       "       [-0.44252044],\n",
       "       [-0.7568025 ],\n",
       "       [-0.95160207],\n",
       "       [-0.99616461],\n",
       "       [-0.88345466],\n",
       "       [-0.63126664],\n",
       "       [-0.2794155 ],\n",
       "       [ 0.1165492 ],\n",
       "       [ 0.49411335],\n",
       "       [ 0.79366786],\n",
       "       [ 0.96791967],\n",
       "       [ 0.98935825],\n",
       "       [ 0.85459891],\n",
       "       [ 0.58491719],\n",
       "       [ 0.22288991],\n",
       "       [-0.17432678],\n",
       "       [-0.54402111]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們將建立訓練數據，其中x是輸入序列，y是目標序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.Tensor(data[:-1]).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.Tensor(data[1:]).type(dtype), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 說明Variable強大功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable # torch 中 Variable 模块\n",
    "\n",
    "# 先生鸡蛋\n",
    "tensor = torch.FloatTensor([[1,2],[3,4]])\n",
    "# 把鸡蛋放到篮子里, requires_grad是参不参与误差反向传播, 要不要计算梯度\n",
    "variable = Variable(tensor, requires_grad=True)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.5000)\n",
      "tensor(7.5000, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "t_out = torch.mean(tensor*tensor)       # x^2\n",
    "v_out = torch.mean(variable*variable)   # x^2\n",
    "print(t_out)\n",
    "print(v_out)    # 7.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable計算時搭配computational graph，將所有反向傳播的結點連接起來，方便一次把梯度都計算出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_out.backward() \n",
    "#d(v_out)/d(variable) = 1/4*2*variable = variable/2\n",
    "#Tensor也可以計算，但是無法作backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(variable.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "#各種variable形式\n",
    "print(variable)  # Variable 形式\n",
    "print(variable.data)  # data 形式\n",
    "print(variable.data.numpy()) # numpy 形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 說明Variable強大功能(結束)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90929743],\n",
       "       [ 0.67546318],\n",
       "       [ 0.33498815],\n",
       "       [-0.05837414],\n",
       "       [-0.44252044],\n",
       "       [-0.7568025 ],\n",
       "       [-0.95160207],\n",
       "       [-0.99616461],\n",
       "       [-0.88345466],\n",
       "       [-0.63126664],\n",
       "       [-0.2794155 ],\n",
       "       [ 0.1165492 ],\n",
       "       [ 0.49411335],\n",
       "       [ 0.79366786],\n",
       "       [ 0.96791967],\n",
       "       [ 0.98935825],\n",
       "       [ 0.85459891],\n",
       "       [ 0.58491719],\n",
       "       [ 0.22288991],\n",
       "       [-0.17432678],\n",
       "       [-0.54402111]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "我們需要創建兩個權重矩陣，w1的大小（input_size，hidden_​​size）用於輸入到隱藏連接，而w2矩陣的大小（hidden_​​size，output_size）用於隱藏到輸出連接。使用具有零均值的正態分佈初始化權重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化\n",
    "w1 = torch.FloatTensor(input_size, hidden_size).type(dtype)\n",
    "init.normal_(w1, 0.0, 0.4) # init.normal 舊版  mean=0.0, std=0.4 (低離散程度)\n",
    "w1 =  Variable(w1, requires_grad=True) #requires_grad=True 需要反向傳播\n",
    "w2 = torch.FloatTensor(hidden_size, output_size).type(dtype)\n",
    "init.normal_(w2, 0.0, 0.4) # init.normal 舊版 mean=0.0, std=0.3 (低離散程度)\n",
    "w2 = Variable(w2, requires_grad=True) #requires_grad=True 需要反向傳播\n",
    "# w1作為輸入，w2最為輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5965],\n",
       "        [-0.2055],\n",
       "        [-0.2924],\n",
       "        [-0.1614],\n",
       "        [-0.0427],\n",
       "        [ 0.0236]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們現在可以定義forward方法，它將輸入向量，context_state為Autograd的結果，整合兩個權重矩陣作為參數。我們將通過將輸入向量與context_state向量連接來創建向量xh。我們在xh向量和權重矩陣w1之間執行點積，然後將tanh函數應用為非線性，這對於RNN而言比sigmoid更好。然後我們在新的context_state和權重矩陣w2之間執行另一個點積。我們想要預測連續值，所以我們在這個階段不應用任何非線性。\n",
    "\n",
    "請注意，context_state將用於在下一個時間步驟填充上下文神經元。這就是我們返回context_state向量以及網絡輸出的原因。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context_state\n",
    "#Variable(torch.zeros((1, hidden_size)).type(dtype), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(input, context_state, w1, w2):\n",
    "  xh = torch.cat((input, context_state), 1) #將input與context_state做連接，並成為列(Row)呈現\n",
    "  context_state = torch.tanh(xh.mm(w1)) #先對w1作內積，相近的數值就接近，再轉換tanh收斂到-1~1\n",
    "  out = context_state.mm(w2) #再對w2做內積作為輸出\n",
    "  return  (out, context_state) #回傳context_state與out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.cat 快速說明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6497,  0.2220, -0.1584,  0.0877,  0.1764, -1.7362],\n",
       "        [-0.1475,  2.0566, -0.1578,  0.6652,  0.3990,  1.2273],\n",
       "        [-1.4531,  1.5406,  0.2388,  1.0145,  1.7663, -0.5078],\n",
       "        [-0.9400, -0.7034,  0.1799, -1.6558,  1.1217, -1.5902]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = torch.randn(4, 6)\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6497,  0.2220, -0.1584,  0.0877,  0.1764, -1.7362],\n",
       "        [-0.1475,  2.0566, -0.1578,  0.6652,  0.3990,  1.2273],\n",
       "        [-1.4531,  1.5406,  0.2388,  1.0145,  1.7663, -0.5078],\n",
       "        [-0.9400, -0.7034,  0.1799, -1.6558,  1.1217, -1.5902],\n",
       "        [-0.6497,  0.2220, -0.1584,  0.0877,  0.1764, -1.7362],\n",
       "        [-0.1475,  2.0566, -0.1578,  0.6652,  0.3990,  1.2273],\n",
       "        [-1.4531,  1.5406,  0.2388,  1.0145,  1.7663, -0.5078],\n",
       "        [-0.9400, -0.7034,  0.1799, -1.6558,  1.1217, -1.5902],\n",
       "        [-0.6497,  0.2220, -0.1584,  0.0877,  0.1764, -1.7362],\n",
       "        [-0.1475,  2.0566, -0.1578,  0.6652,  0.3990,  1.2273],\n",
       "        [-1.4531,  1.5406,  0.2388,  1.0145,  1.7663, -0.5078],\n",
       "        [-0.9400, -0.7034,  0.1799, -1.6558,  1.1217, -1.5902]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x_t, x_t, x_t), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6497,  0.2220, -0.1584,  0.0877,  0.1764, -1.7362, -0.6497,  0.2220,\n",
       "         -0.1584,  0.0877,  0.1764, -1.7362, -0.6497,  0.2220, -0.1584,  0.0877,\n",
       "          0.1764, -1.7362],\n",
       "        [-0.1475,  2.0566, -0.1578,  0.6652,  0.3990,  1.2273, -0.1475,  2.0566,\n",
       "         -0.1578,  0.6652,  0.3990,  1.2273, -0.1475,  2.0566, -0.1578,  0.6652,\n",
       "          0.3990,  1.2273],\n",
       "        [-1.4531,  1.5406,  0.2388,  1.0145,  1.7663, -0.5078, -1.4531,  1.5406,\n",
       "          0.2388,  1.0145,  1.7663, -0.5078, -1.4531,  1.5406,  0.2388,  1.0145,\n",
       "          1.7663, -0.5078],\n",
       "        [-0.9400, -0.7034,  0.1799, -1.6558,  1.1217, -1.5902, -0.9400, -0.7034,\n",
       "          0.1799, -1.6558,  1.1217, -1.5902, -0.9400, -0.7034,  0.1799, -1.6558,\n",
       "          1.1217, -1.5902]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x_t, x_t, x_t), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.cat 快速說明結束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們的建立循環結構如下。\n",
    "\n",
    "在每個迭代的開始，為了確保context_state是乾淨的，我們需要用初始化我們的context_state向量。\n",
    "\n",
    "環遍歷序列的每個元素。我們前進的方法執行返回將用於下一個步驟的預測和context_state的前向傳遞。然後我們計算均方誤差（MSE），當我們想要預測連續值時，這是一個自然的選擇。通過在損失上運行backward（）方法我們計算梯度，然後我們更新權重。我們應該通過調用zero_（）方法清除每次迭代的漸變，否則將累積漸變。我們做的最後一件事是將context_state向量包裝在新的Variable中，以將其從歷史記錄中分離出來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 loss 1.2071304321289062\n",
      "tensor([[-0.6312],\n",
      "        [-0.3480],\n",
      "        [-0.2185],\n",
      "        [-0.1919],\n",
      "        [-0.1722],\n",
      "        [ 0.1395]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerrywu2018/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 loss 0.015333490446209908\n",
      "tensor([[-0.5041],\n",
      "        [-0.4300],\n",
      "        [ 0.1002],\n",
      "        [-0.1007],\n",
      "        [-0.5802],\n",
      "        [ 0.0794]], requires_grad=True)\n",
      "Epoch: 200 loss 0.0076925186440348625\n",
      "tensor([[-0.4728],\n",
      "        [-0.4341],\n",
      "        [ 0.1168],\n",
      "        [-0.0699],\n",
      "        [-0.6546],\n",
      "        [ 0.1180]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "  total_loss = 0\n",
    "  #裝RNN的資料context_state\n",
    "  context_state = Variable(torch.zeros((1, hidden_size)).type(dtype), requires_grad=True)\n",
    "    #起始為0  0  0  0  0  0 因為hidden_size設定為6\n",
    "  for j in range(x.size(0)): #x.size(0)確保是正確數字\n",
    "    input = x[j:(j+1)] #依序將0.9093、0.6755取出\n",
    "    target = y[j:(j+1)] #依序將0.6755、0.3350、-0.0584、-0.4425取出\n",
    "    (pred, context_state) = forward(input, context_state, w1, w2)\n",
    "    #實際-預測 計算Loss MSE\n",
    "    loss = (pred - target).pow(2).sum()/2\n",
    "    total_loss += loss\n",
    "    loss.backward()\n",
    "    #加上學習速率，加得越大數值跳越快，權重重新產生\n",
    "    w1.data -= lr * w1.grad.data \n",
    "    w2.data -= lr * w2.grad.data\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()\n",
    "    context_state = Variable(context_state.data)\n",
    "  if i % 100 == 0: #取餘數，讓他變成10次顯示一次\n",
    "     print(\"Epoch: {} loss {}\".format(i, total_loss.data[0]))\n",
    "     print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "  total_loss = 0\n",
    "  context_state = Variable(torch.zeros((1, hidden_size)).type(dtype), requires_grad=True)\n",
    "  for j in range(x.size(0)): \n",
    "    input = x[j:(j+1)] \n",
    "    target = y[j:(j+1)] \n",
    "    (pred, context_state) = forward(input, context_state, w1, w2)\n",
    "    loss = (pred - target).pow(2).sum()/2\n",
    "    total_loss += loss\n",
    "    loss.backward()\n",
    "    w1.data -= lr * w1.grad.data \n",
    "    w2.data -= lr * w2.grad.data\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()\n",
    "    context_state = Variable(context_state.data)\n",
    "  if i % 100 == 0:\n",
    "     print(\"Epoch: {} loss {}\".format(i, total_loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練期間產生的輸出顯示每個時期的損失如何減少，這是一個好兆頭。衰退損失意味著我們的模型正在學習。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦我們的模型被訓練，我們就可以進行預測，在序列的每個步驟中，我們將使用單個數據點為模型提供信息，並要求模型在下一個時間步驟預測一個值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_state = Variable(torch.zeros((1, hidden_size)).type(dtype), requires_grad=False)\n",
    "predictions = []\n",
    "\n",
    "for i in range(x.size(0)):\n",
    "  input = x[i:i+1]\n",
    "  (pred, context_state) = forward(input, context_state, w1, w2) #w1,w2是由上面帶下來的數值\n",
    "  context_state = context_state\n",
    "  predictions.append(pred.data.numpy().ravel()) #透過data.numpy將pred轉numpy,透過數據ravel整理一下\n",
    "  #print(\"predictions==========\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data_time_steps為x軸,x.data.numpy為Y軸\n",
    "pl.scatter(data_time_steps[:-1], x.data.numpy(), s=90, label=\"Actual\") # s= 圈圈大小\n",
    "pl.scatter(data_time_steps[1:], predictions, label=\"Predicted\")\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
